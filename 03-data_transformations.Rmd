# Data transformations

```{r libraries and data, message=TRUE, warning=FALSE}
# improt libraries
library(tidymodels)
library(tidyverse)

# import and prepare data
# import data
unbalanced_data <- read_csv("./data/train_full.csv") %>% select(-...1, -session_id)
balanced_data <- read_csv("./data/train_balanced.csv") %>% select(-...1, -session_id)

```

The findings from the data exploration stage will be used to preprocess the data to be used for each model. Each model requires a set of specific transformation and each algorithm treats imputs differently (eg: Nearest Neigbors are sensible to scale, while naives bayes is not) so the pre process should be consider on a model experiment base.

Post-processing and model definition will be done on the next stage.

A number of key prepocess transformations are considered:
- feature selection and reducion. This is made using domain knowledge and looking at correlation between features. Nonetheless there is a test using full model. If not based on domain knowledge will use PCA transform.

- imputation of missing data when needed

- Scale and center features when required by the model

- Transform skwed features specially for models where variance plays a role or rely on gaussian (linear model). Given the business focus of interpreting the model (focus on inference) when possible will use log transform instead of more complex Box Plot transforms $\lambda$.

## Summary of transformation steps identified during EDA

The following transformations were indentified during the EDA stage:

- Features *Device Group* and *Platform* showed a strong relationship between them. Given that *Platform* provides more information *Device Group will be removed*
- Features starting with *"has_"* refere to milestones on customer journey, therefore the need to include all of them should be taken in consideration. We will use PCA to merge this into one feature and experimente between the use of them individual or together,
- *Duration* feature is Right Skewed and contains observations which lack business sense. To avoid any impact on the model, specially on ones more sensible to variance, it will be log transformed and observations above 24hours will be removed
- Replace all *Missing values* on *country*, *browser_name* and *is_subscribed* using Nearest Neighbors imputation with a very a k of 3,
- Reduce the number of observations of class country and browser_name by compressing smaller ones into a generic class named others. This will be done because some models do not manage very well the fact that some dummy variables only have one level
- Specially for the use of Neural Networks and Supervisor Vector Machines, numeric variables will be normalized and scaled
- Converts unique_browse_designer_qty, unique_product_qty, unique_browse_designer_qty, unique_browse_category_qty to ratios over Total Pageviews (view_qty) which provides information on the ammount of page views actually related to that category,
- Adds new variable to classify a session as bounce. A bounce is defined commonly as a session with a single page view (or one hit)

```{r}

# For balanced data and to be used generically for all models
preprocess <- 
  recipe( bought ~ . , data = balanced_data) %>% 
  step_log(duration, view_qty, unique_qty, unique_browse_designer_qty) %>% 
  step_filter(duration > 60 * 60 * 24) %>% 
  step_impute_knn(all_predictors(), neighbors = 3) %>% 
  step_pca(starts_with("has_")) %>% 
  step_other(country, treshdold = 0.01) %>% 
  step_other(browser_name, treshold = 0.01) %>% 
  step_mutate_at(starts_with("unique_"), fn = ~ ./view_qty) %>% 
  step_mutate(is_bounce = ifelse(view_qty == 1, 1, 0))  

preprocess_logit_nn <- 
  preprocess %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_scale(all_numeric_predictors())

preprocess_mlp_svm <- 
  preprocess %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_normalize(all_numeric_predictors()) %>% 
  step_scale(all_numeric_predictors())

```

```{r}

tidy(preprocess)

``` 


```{r}

tidy(preprocess_logit_nn)

```


```{r}

tidy(preprocess_mlp_svm)

``` 
